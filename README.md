# spark_homework
Сборка витрины на PySpark

Для запуска использовал  https://github.com/cluster-apps-on-docker/spark-standalone-cluster-on-docker

Приложен ноутбук, в котором визуально виден результат выполнения операций.

Входной точкой для запуска spark-submit является run.sh, указывается 2 позиционных агрумента - папка откуда читаем файлы и куда записываем результат
Далее run.sh запускает сабмит с использованием main.py
